To begin our progression towards random forests, we first examine learning with a single classification and regression tree (CART). To build a tree, we must apply a series of cuts to the dataset to partition it into groups. There are several ways to build a tree, one being the retention of a domain expert to create the tree based on judgement calls (in our case, this would possibly be a realtor from the Ames area). Falling short of that, a powerful decision tree algorithm developed by Quinlan known as ID3 (and its successor C4.5, also developed by Quinlan) provide a logical way to create a classification tree without an expert. The algorithm works on categorical data by using concepts derived from Information Theory, specifically entropy and information gain. Entropy is defined as 
